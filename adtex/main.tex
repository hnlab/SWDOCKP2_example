% 'nonacm' to remove any running header
\documentclass[nonacm,sigconf]{acmart}

% \usepackage{cite}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{tagging}
\usepackage{hyperref}
\usepackage{sc25repro}
\pagenumbering{gobble} % no page numbers

% Uncomment/comment the following usetag lines
% if you would like to get an explanation or an example.
% Don't forget to comment them for the final submission.
% \usetag{explanation}
% \usetag{example}

\begin{document}

\twocolumn[%
{\begin{center}
\Huge
Appendix: Artifact Description/Artifact Evaluation
\end{center}}
]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  AD Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendixAD

\section{Overview of Contributions and Artifacts}

\subsection{Paper's Main Contributions}
\begin{description}
\item[$C_1$] A novel energy grid alignment strategy enables parallel processing of multiple receptors by fully exploiting SIMD (Single Instruction Multiple Data) capabilities and maximizing DMA (Direct Memory Access) communication bandwidth. This significantly reduces the I/O and pose matching costs in ensemble docking while maintaining consistent results compared to separate single-receptor docking.

\item[$C_2$] A novel trilinear SIMD interpolation algorithm and a performance portable layer to maintain the compatibility and efficiency of SWDOCK across multiple platforms beyond Sunway supercomputers.

\item[$C_3$] A reorganization of the DB2 data structure for storing ligand conformations by sorting and merging the basic conformational components. This approach nearly reduces iteration times by 50\% during the scoring phase of docking.

\item[$C_4$] An ``early bump'' mechanism to identifies and dismisses clashing atoms, effectively eliminating unnecessary computations for conformations containing unfavorable high-energy components.

\item[$C_5$] A cache scheme that stores the scores of commonly-used conformational components in the fast-access local data memory (LDM) to accelerate the scoring phase.

\item[$C_6$] AthreadS framework is implemented, which is useful for porting Sunway-optimized programs to homogeneous platforms, bridging architectural gaps while preserving performance efficiency.
\end{description}

\artexpl{
Provide a list of all main contributions of the paper.
}

\artsampl{
\begin{description}
\item[$C_1$] This is the 1st contribution.
\item[$C_2$] This is the 2nd contribution.
\item[$C_3$] This is the 3rd contribution.
\end{description}
}


\subsection{Computational Artifacts}
\begin{description}
\item[$A_1$] \href{https://github.com/hnlab/SWDOCKP2_example}{https://github.com/hnlab/SWDOCKP2\_example}
\end{description}

\begin{center}
\begin{tabular}{rll}
\toprule
Artifact ID  &  Contributions &  Related \\
             &  Supported     &  Paper Elements \\
\midrule
$A_1$   &  All & Figure 3-6 12 \\
\bottomrule
\end{tabular}
\end{center}

\artexpl{
List the computational artifacts related to this paper along with their respective DOIs. Note that all computational artifacts may be archived under a single DOI.
}

\artsampl{
\begin{description}
\item[$A_1$] https://doi.org/YY.YYYY/zenodo.0XXXXX
\item[$A_2$] https://doi.org/ZZ.YYYY/zenodo.1XXXXX
\item[$A_3$] https://doi.org/ZZ.YYYY/zenodo.2XXXXX
\end{description}
}

\artexpl{
Provide a table with the relevant computational artifacts,
highlight their relation to the contributions (from above) and
point to the elements in the paper that are reproducible by each artifact, e.g.,
which figures or tables were generated with the artifact.
}

\artsampl{
\begin{center}
\begin{tabular}{rll}
\toprule
Artifact ID  &  Contributions &  Related \\
             &  Supported     &  Paper Elements \\
\midrule
$A_1$   &  $C_1$ & Tables 1-2 \\
        &        & Figure 3\\
\midrule
$A_2$   &  $C_2$ & Tables 2-3 \\
        &        & Figures 1-2\\
\midrule
.. \\
\bottomrule
\end{tabular}
\end{center}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Artifact Identification}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\artexpl{
Provide the following six subsections for each computational artifact $A_i$.
}

\newartifact

\artrel
This artifact encompasses two x86 compilations of SWDOCKP\textsuperscript{2}, designed to support a maximum of 4 and 8 targets respectively for parallel processing. Accompanying these two compilations is a computational case study involving the docking of 296 db2 hierarchies against four conformations of the SARS-CoV-2 Main Protease.

To comprehensively showcase the performance of the eight-target compilation, we replicated the target-related files as its input. These compilations are based on a specific version of the source code that incorporates all available code-level optimization strategies.

Two variants of the ligand database are supplied: the unprocessed (raw) version and the optimized version, which has undergone conformation sorting and merging as is mentioned in the paper. This artifact effectively demonstrates the enhanced efficiency and performance portability of SWDOCKP\textsuperscript{2}.

\artexpl{
    Briefly explain the relationship between the artifact and contributions.
}

\artexp
Both compilations are expected to exhibit faster execution on the optimized db2 database compared to the raw version. More precisely, the four-target compilation is anticipated to achieve a marginally higher processing speed and significantly lower memory consumption when contrasted with the eight-target compilation.

\artexpl{
Provide a higher level description of what outcome to expect from the corresponding experiments. Provide an explanation of how the results substantiate the main contributions.
}

\artsampl{
Algorithm A should be faster than Algorithms C and B in all GPU scenarios.
}

\arttime
On an AMD EPYC 9654 processor, with a single process utilizing 16 threads, the four-target compilation required 0.10 minutes (6.0 seconds) and 0.13 minutes (7.8 seconds) to complete docking the optimized database and the raw database, respectively. In comparison, the eight-target compilation took 0.13 minutes (7.8 seconds) and 0.16 minutes (9.5 seconds) for the same tasks, respectively.
\artexpl{
Estimate the time required to reproduce the artifact, providing separate estimates for the individual steps: Artifact Setup, Artifact Execution, and Artifact Analysis.
}

\artsampl{
The expected computational time of this artifact on GPU X is 20~min.
}

\artin

\artinpart{Hardware}
A CPU with x86 architecture that supports multi-threading is necessary for execution.

\artexpl{
Specify the hardware requirements and dependencies (e.g., a specific interconnect or GPU type is required).
}

\artinpart{Software} The system environment must have glibc version 2.28 or higher, and mpich version 4.2.0 or higher to successfully run this artifact.

\artexpl{
Introduce all required software packages, including the computational artifact. For each software package, specify the version and provide the URL.
}

\artinpart{Datasets / Inputs}
The provided ligand .db2 datasets are originally sourced from ZINC library \cite{irwin2012zinc, sterling2015zinc}. Subsequently, they are transposed and compressed into the .xz format, as detailed in reference \cite{xu2022redesigning}. The optimized version of the datasets is created through the process of sorting and merging conformations, as described in the accompanying paper.
For proper execution, the working directory should contain an input parameter file named INDOCK and the paths to all input ligand .db2 files. For more comprehensive details regarding the input structure and file requirements, please refer to the GitHub repository mentioned in section 1.2. All relevant files are included within this repository.
\artexpl{
Describe the datasets required by the artifact. Indicate whether the datasets can be generated, including instructions, or if they are available for download, providing the corresponding URL.
}

\artinpart{Installation and Deployment} The GitHub repository contains all the necessary non - glibc dynamic libraries. The linkage paths for these libraries have been pre-configured via the LD\_LIBRARY\_PATH environment variable within the provided execution scripts.

\artexpl{
Detail the requirements for compiling, deploying, and executing the experiments, including necessary compilers and their versions.
}

\artcomp
Users can directly execute the provided scripts to run the artifact without installation.
\artexpl{
Provide an abstract description of the experiment workflow of the artifact. It is important to identify the main tasks (processes) and how they depend on each other.

A workflow may consist of three tasks: $T_1, T_2$, and $T_3$. The task $T_1$ may generate a specific dataset. This dataset is then used as input by a computational task $T_2$, and the output of $T_2$ is processed by another task $T_3$, which produces the final results (e.g., plots, tables, etc.). State the individual tasks $T_i$ and provide their dependencies, e.g., $T_1 \rightarrow T_2 \rightarrow T_3$.

Provide details on the experimental parameters. How and why were parameters set to a specific value (if relevant for the reproduction of an artifact), e.g., size of dataset, number of data points, input sizes, etc. Additionally, include details on statistical parameters, like the number of repetitions.
}

\artout
The artifact will generate the following output files:
\begin{itemize}
    \item \textit{x}OUTDOCK: Docking scores generated by process \textit{x}.
    \item \textit{x}mpro\_rec\_\textit{y}.mol2.gz: Gzip-compressed docking poses in .mol2 format for target \textit{y}, produced by process \textit{x}. The order of these poses corresponds to that in \textit{x}OUTDOCK.
\end{itemize}
The processing time is computed by subtracting the start time from the end time, where both times are retrieved using the \textit{gettimeofday()} function from the \textit{<sys/time.h>} library. The resulting time value, expressed in seconds, is then outputted to both the \textit{x}OUTDOCK file and the standard output (stdout).

Upon the utilization of multiple MPI processes, the time expenditure of each process may differ due to the task allocation strategy implemented in SWDOCKP\textsuperscript{2}. The specific wall time for process \textit{x} is presented at the end of the \textit{x}OUTDOCK file, succeeded by the total elapsed time for all processes to termicate.

Analogously, the durations for ligand loading, minimization operations, and the entire search procedure across all processes are calculated. These time metrics are printed to stdout in the sequence corresponding to the termination order of the processes.

% \newartifact

% \artexpl{
% Provide the same type of information as done for Computational Artifact $A_1$.
% }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  AE Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \newpage
% \appendixAE

% \arteval{1}
% \artin

% \artexpl{
% Provide instructions for installing and compiling libraries and code.
% Offer guidelines on deploying the code to resources.
% }

% \artcomp

% \artexpl{
% Describe the experiment workflow.
% If encapsulated within a workflow description or equivalent (such as a makefile or script), clearly outline the primary tasks and their interdependencies. Detail the main steps in the workflow. Merely instructing to “Run script.sh” is inadequate.
% }

% \artout

% \artexpl{
% \begin{itemize}
%     \item Provide a description of the expected results and a methodology for evaluating these results.
%     \item Explain how the expected results from the experiment workflow correlate with the contributions stated in the article.
%     \item For example, if the article presents results in a figure, the artifact evaluation should also produce a similar figure, depicting the same generalizable outcome. Authors must focus on these aspects to reduce the time required for others to understand and verify an artifact.
% \end{itemize}
% }


% \arteval{2}
% \artin
% \artcomp
% \artout

\bibliographystyle{IEEEtran}
\bibliography{refs.bib}

\end{document}